{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_prep = pd.read_csv(\"weather_data_prep.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert DATE column into Date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_prep['DATE']= pd.to_datetime(weather_data_prep['DATE']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop useless columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We think SNOW, SNWD (Snow Depth) and PGTM (Peak gust time) are useless because it's null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_prep = weather_data_prep.drop(['SNWD', 'PGTM', 'SNOW'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_prep = weather_data_prep.groupby(['DATE']).agg({\n",
    "    'AWND': 'mean',\n",
    "    'PRCP':'mean',\n",
    "    'TAVG': 'mean',\n",
    "    'WDF5': 'mean',\n",
    "    'TMAX':'max',\n",
    "    'WSF2': 'max',\n",
    "    'WSF5': 'max',\n",
    "    'WT01': 'max',\n",
    "    'WT02': 'max',\n",
    "    'WT03': 'max',\n",
    "    'WT08': 'max',\n",
    "    'TMIN': 'min'\n",
    "})\n",
    "\n",
    "\n",
    "weather_data_prep = weather_data_prep.rename(columns={\n",
    "    \"AWND\": \"AWND_mean\", \n",
    "    \"PRCP\": \"PRCP_mean\", \n",
    "    \"TAVG\": \"TAVG_mean\", \n",
    "    \"WDF5\": \"WDF5_mean\", \n",
    "    \"TMAX\": \"TMAX_max\",\n",
    "    'WSF2': 'WSF2_max',\n",
    "    'WSF5': 'WSF5_max',\n",
    "    'WT01': 'WT01_max',\n",
    "    'WT02': 'WT02_max',\n",
    "    'WT03': 'WT03_max',\n",
    "    'WT08': 'WT08_max',\n",
    "    'TMIN': 'TMIN_min'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add two informations that might affect the prediction: if there is snow or rain that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_prep['IceRoad'] = np.where(weather_data_prep['TMIN_min'] < 37.4, 1, 0)\n",
    "weather_data_prep['WetDay'] = np.where(weather_data_prep['PRCP_mean'] > 0, 1, 0)\n",
    "weather_data_prep = weather_data_prep.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load airport dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_Data = pd.read_csv(\"Test_Set_Airport_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We drop useless columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_Data = Airport_Data.drop([\n",
    "    'stand_last_change', \n",
    "    'sto',\n",
    "    'atot',\n",
    "    'aobt',\n",
    "    'chocks_on',\n",
    "    'stand_scheduled',\n",
    "    'last_distance_to_gate',\n",
    "    'last_in_sector',\n",
    "    'status',\n",
    "    'mode_s',\n",
    "    'acReg',\n",
    "    'partition',\n",
    "    'vdgs_in',\n",
    "    'stand_active',\n",
    "    'stand_docking',\n",
    "    'aibt_received',\n",
    "    'sqt',\n",
    "    'plb_on',\n",
    "    'pca_on',\n",
    "    'gpu_on',\n",
    "    'towbar_on',\n",
    "    'plb_off',\n",
    "    'pca_off',\n",
    "    'gpu_off',\n",
    "    'acars_out',\n",
    "    'vdgs_out',\n",
    "    'stand_free',\n",
    "    'eobt',\n",
    "    'aldt_received',\n",
    "    'stand_prepared',\n",
    "    'stand_auto_start',\n",
    "    'roll',\n",
    "    'speed'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We add Date column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_Data['DATE'] = pd.to_datetime(Airport_Data['aldt'], errors='coerce').dt.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_and_weather = pd.merge(Airport_Data, weather_data_prep, how='left', on=['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_and_weather = Airport_and_weather.rename(columns={\n",
    "    \"carrier\": \"Airline\", \n",
    "    \"flight\": \"FlightNumber\", \n",
    "    \"DATE\": \"Date\", \n",
    "    \"acType\": \"AircraftType\", \n",
    "    \"ship\": \"ShipmentWeight\",\n",
    "    'runway': 'Runway',\n",
    "    'stand': 'Stand',\n",
    "    'aldt': 'ActualLandingTime',\n",
    "    'eibt': 'EstimatedInBlockTime',\n",
    "    'cibt': 'CalculatedInBlockTime',\n",
    "    'aibt': 'ActualInBlockTime'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We calculate the Taxi time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_and_weather['TaxiTime'] = pd.to_datetime(Airport_and_weather['ActualInBlockTime'], errors='coerce') - pd.to_datetime(Airport_and_weather['ActualLandingTime'], errors='coerce')\n",
    "\n",
    "Airport_and_weather['TaxiTime'] = Airport_and_weather['TaxiTime'].dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop duplicates and the rows containing NAN values for Taxi time, and the rows containing absurd taxi times values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_and_weather = Airport_and_weather.drop_duplicates()\n",
    "Airport_and_weather = Airport_and_weather[np.isfinite(Airport_and_weather['TaxiTime'])]\n",
    "Airport_and_weather = Airport_and_weather[(Airport_and_weather['TaxiTime'] >= 0) & (Airport_and_weather['TaxiTime'] < 120)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate into groups the planes according to their shipment weight, which might affect the taxi time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (pd.to_numeric(Airport_and_weather['ShipmentWeight'], errors='coerce') < 2000),\n",
    "    (pd.to_numeric(Airport_and_weather['ShipmentWeight'], errors='coerce') >= 2000) & (pd.to_numeric(Airport_and_weather['ShipmentWeight'], errors='coerce') < 6000),\n",
    "    (pd.to_numeric(Airport_and_weather['ShipmentWeight'], errors='coerce') >= 6000)]\n",
    "\n",
    "choices = ['S', 'M', 'L']\n",
    "\n",
    "Airport_and_weather['ShipmentWeightCat'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add the number of planes which arrive 10mn before the one in the row. If there is a lot of planes that are landing at the same time, it will affect the taxi time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_and_weather['ActualLandingTime'] = pd.to_datetime(Airport_and_weather['ActualLandingTime'], errors='coerce')\n",
    "Airport_and_weather = Airport_and_weather.sort_values(by='ActualLandingTime').set_index('ActualLandingTime')\n",
    "Airport_and_weather['NbPlanesLast10Mn'] = Airport_and_weather['TaxiTime'].rolling(\"10T\").count()\n",
    "Airport_and_weather = Airport_and_weather.reset_index()\n",
    "\n",
    "Airport_and_weather['NbPlanesLast10Mn'] = Airport_and_weather['NbPlanesLast10Mn'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a column with the day of the week (from 0 on monday to 6 on sunday) and the month of the year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_and_weather['Hour'] = Airport_and_weather['ActualLandingTime'].dt.hour\n",
    "Airport_and_weather['DayOfTheWeek'] = Airport_and_weather['ActualLandingTime'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform Runway into a numeric values for the model as well as the stand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_and_weather['Runway'] = pd.to_numeric(Airport_and_weather['Runway'].str[7:9], errors='coerce')\n",
    "Airport_and_weather = Airport_and_weather.rename(columns={\n",
    "    \"Runway\": \"RunwayNumber\"\n",
    "})\n",
    "\n",
    "\n",
    "Airport_and_weather['Stand'] =  pd.to_numeric(Airport_and_weather['Stand'].str[5:], errors='coerce')\n",
    "\n",
    "Airport_and_weather = Airport_and_weather.rename(columns={\n",
    "    \"Stand\": \"StandNumber\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop Tmax_max and tmin_min because highly correlated with tavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_and_weather['FlightNumber'] = pd.to_numeric(Airport_and_weather['FlightNumber'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_and_weather = Airport_and_weather.drop([\n",
    "    'FlightNumber', \n",
    "    'EstimatedInBlockTime',\n",
    "    'CalculatedInBlockTime',\n",
    "    'ActualInBlockTime',\n",
    "    'TMAX_max',\n",
    "    'TMIN_min',\n",
    "    'ShipmentWeight'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the log of the taxi time in order to have a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_and_weather['LogTaxiTime'] = np.log(Airport_and_weather['TaxiTime'] + 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We now merge with airfacts data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the name of the aircrafts on the two files provided (ACchar.xlsx & Airport_Data.csv), we created a file containing the same name and the aircrafts specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aircrafts_info = pd.read_csv(\"aircraft_simplified_data.csv\", sep=\";\",header=0,encoding = 'unicode_escape')\n",
    "Aircrafts_info = Aircrafts_info.rename(columns={\n",
    "    \"Model_Airport_Data\": \"AircraftType\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalDataset = pd.merge(Airport_and_weather, Aircrafts_info, how='left', on=['AircraftType'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter dates that had obviously a problem and which are not relevant for the predictions (the average of the taxi time these days are more than 20 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalDataset = FinalDataset[FinalDataset['Date'] != \"2018-09-26\"]\n",
    "FinalDataset = FinalDataset[FinalDataset['Date'] != \"2018-08-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final data preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rename the columns, drop the columns that are not correlated with parking area(wingspan and length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns renaming: \n",
    "FinalDataset.rename(columns={'Parking Area':'ParkingArea',\n",
    "                             'WT01_max':'WT01max',\n",
    "                             'WT02_max':'WT02max', \n",
    "                             'WT03_max':'WT03max', \n",
    "                             'WT08_max':'WT08max', \n",
    "                             'WSF2_max':'WSF2max', \n",
    "                             'WSF5_max':'WSF5max',\n",
    "                             'Model_Acchar':'ModelAcchar',  \n",
    "                             'TAVG_mean':'TAVGmean',\n",
    "                             'AWND_mean':'AWNDmean', \n",
    "                             'TAVG_mean':'TAVGmean', \n",
    "                             'DayOfTheWeek':'WeekDay',\n",
    "                             'WDF5_mean':'WDF5mean', \n",
    "                             'PRCP_mean':'PRCPmean'}, inplace=True)\n",
    "\n",
    "# Dropping correlated variables:  \n",
    "FinalDataset=FinalDataset.drop(labels=[\"Wingspan\",\"Length\"], axis=1)\n",
    "\n",
    "# Converting dates to_datetime: \n",
    "FinalDataset.ActualLandingTime=pd.to_datetime(FinalDataset.ActualLandingTime.values)\n",
    "FinalDataset.Date=pd.to_datetime(FinalDataset.Date.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop nan values except for the weather where a null just means that it is equal to 0 (example for the rain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dropping (real) NA values ~4%: \n",
    "FinalDataset=FinalDataset.dropna(subset=[\"RunwayNumber\", \"StandNumber\", \"AircraftType\",\"ParkingArea\"])\n",
    "\n",
    "# Filling other missing values with 0 : \n",
    "FinalDataset=FinalDataset.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stand Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stand importance in the taxi time result is analyzed to extract 4 different classes of stand : \"very close\", \"close\", \"far\", \"very far\", based on the last average taxi time result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StandAnalysis = FinalDataset.loc[:,[\"StandNumber\",\"TaxiTime\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SortedStand = StandAnalysis.groupby(\"StandNumber\").mean().reset_index().sort_values(\"TaxiTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FirstGroup = SortedStand.iloc[0:40,:].loc[:,\"StandNumber\"].to_list()\n",
    "SecondGroup = SortedStand.iloc[40:80,:].loc[:,\"StandNumber\"].to_list()\n",
    "ThirdGroup = SortedStand.iloc[80:120,:].loc[:,\"StandNumber\"].to_list()\n",
    "ForthGroup = SortedStand.iloc[120:,:].loc[:,\"StandNumber\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stands = FinalDataset[\"StandNumber\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StandRank = []\n",
    "for i in range(len(Stands)):\n",
    "    if Stands[i] in FirstGroup :\n",
    "        StandRank.append(0)\n",
    "    elif Stands[i] in SecondGroup :\n",
    "        StandRank.append(1)\n",
    "    elif Stands[i] in ThirdGroup :\n",
    "        StandRank.append(2)\n",
    "    else :\n",
    "        StandRank.append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalDataset[\"StandRank\"] = StandRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting TaxiTime and LogTaxiTime as last columns : \n",
    "taxitime=FinalDataset.TaxiTime\n",
    "logtaxitime=FinalDataset.LogTaxiTime \n",
    "\n",
    "FinalDataset.drop([\"TaxiTime\", \"LogTaxiTime\", \"ModelAcchar\"], axis=1, inplace=True)\n",
    "\n",
    "FinalDataset[\"TaxiTime\"]=taxitime\n",
    "FinalDataset[\"LogTaxiTime\"]=logtaxitime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = FinalDataset.to_csv('DatasetCleanFinal.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalDataset[FinalDataset.isna() == True].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProfileReport(FinalDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
